# Configuration for Ukrainian Handwritten Text Recognition Training - WITH BACKGROUND NORMALIZATION
# Dataset: 18,691 training lines + 935 validation lines from Ukrainian historical documents
# CRITICAL: Data has been preprocessed with background normalization to match Efendiev dataset (6-7% CER)

# Model
model_name: "kazars24/trocr-base-handwritten-ru"  # Pre-trained Russian model as base
max_length: 128  # Increased for longer Ukrainian lines (avg width: 2262px)

# Data paths - NORMALIZED DATA
data_root: "./data"  # Root data directory
train_csv: "ukrainian_train_normalized/train.csv"  # Training CSV
val_csv: "ukrainian_val_normalized/train.csv"  # Validation CSV

# Performance settings
cache_images: false  # Images are large (2262px avg width), don't cache
num_workers: 4
dataloader_num_workers: 4

# Training hyperparameters
output_dir: "./models/ukrainian_model_normalized"  # CHANGED: Separate output directory
batch_size: 6  # Reduced to 6 to prevent OOM
gradient_accumulation_steps: 4  # Effective batch size: 6*4=24 per GPU
epochs: 20  # More epochs for large dataset
learning_rate: 0.00004
weight_decay: 0.01
warmup_ratio: 0.1
optim: "adafactor"  # Better optimizer for transformers (as in Bullinger)

# Optimization
fp16: true  # Mixed precision for speed
gradient_checkpointing: false

# Evaluation and checkpointing
eval_strategy: "steps"
eval_steps: 500  # Evaluate every 500 steps
save_steps: 500  # Save checkpoint every 500 steps
save_total_limit: 3  # Keep best 3 checkpoints
logging_steps: 50  # Log every 50 steps

# Generation settings
predict_with_generate: true
generation_max_length: 128
generation_num_beams: 4  # Beam search for better quality (as in Bullinger)

# Data augmentation
use_augmentation: true
aug_rotation_degrees: 2
aug_brightness: 0.3
aug_contrast: 0.3

# Reproducibility
seed: 42
