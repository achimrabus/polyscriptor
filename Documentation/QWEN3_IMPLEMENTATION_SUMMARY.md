# Qwen3 VLM Integration - Implementation Summary

## âœ… What Was Implemented

### 1. Enhanced Qwen3 Inference Class ([inference_qwen3.py](inference_qwen3.py))

**Key Features:**
- âœ… Whole-page OCR (no line segmentation needed)
- âœ… **Confidence score estimation** using token probabilities
- âœ… Multi-GPU automatic distribution
- âœ… LoRA/PEFT adapter support for finetuned models
- âœ… Flexible prompt engineering
- âœ… Memory monitoring and management

**Confidence Scores:**
```python
# VLMs can estimate confidence by extracting token log probabilities
result = qwen3.transcribe_page(
    image,
    return_confidence=True  # Extract token-level probabilities
)

print(f"Text: {result.text}")
print(f"Confidence: {result.confidence:.2%}")  # Average across all tokens
```

**How It Works:**
- Extracts `output_scores` during generation
- Applies softmax to get token probabilities
- Gets probability of each selected token
- Averages across all tokens = overall confidence

**Note:** This is an estimate because:
- VLMs don't naturally provide per-character confidence
- Confidence is averaged across BPE tokens (not characters)
- Still useful for gauging overall reliability

### 2. GUI Integration ([transcription_gui_qt.py](transcription_gui_qt.py))

**Added Qwen3 VLM Tab:**
- Model selection dropdown (2B, 8B, finetuned variants)
- Custom adapter input field
- Prompt customization text box
- Advanced settings:
  - Max tokens (512-8192)
  - Image size (512-2048)
  - **"Estimate Confidence" checkbox** â­

**Smart UI Behavior:**
- When Qwen3 tab selected:
  - âœ… Hides line segmentation controls (not needed!)
  - âœ… Changes button text to "Transcribe Page"
  - âœ… Hides line count label
- When switching back to TrOCR/PyLaia:
  - âœ… Shows segmentation controls again
  - âœ… Restores "Process All Lines" button

**Workflow:**
```
1. Load image
2. Select "Qwen3 VLM" tab
3. Choose model (e.g., qwen3-vl-8b)
4. Optionally: Edit prompt, enable confidence
5. Click "Transcribe Page"
6. Wait 10-30 seconds
7. View full page transcription
```

## ðŸŽ¯ Confidence Scores - The Full Picture

### âœ… Available with Confidence Estimation

**Qwen3 VLM:**
- Overall page confidence âœ…
- Token-level probabilities (internal)
- Average across entire transcription
- Enable with checkbox "Estimate Confidence"

**TrOCR:**
- Line-level confidence âœ…
- Per-token confidence âœ…
- Can toggle "Line Average" vs "Per Token" display
- Color-coded visualization

### âŒ Limitations

**Why VLM confidence is harder:**
1. **BPE Tokenization** - Tokens â‰  characters
   - "hello" might be 1 token or 2 ("hel" + "lo")
   - Can't map directly to character positions

2. **Context Dependence** - VLMs use vision+text context
   - Confidence depends on entire image
   - Not just the character itself

3. **Generation Strategy** - Beam search complicates things
   - With num_beams=4, tracks 4 hypotheses
   - Final probability doesn't reflect all paths

### ðŸ’¡ Workarounds for Better Confidence

**Option 1: Multiple Runs (High Quality)**
```python
# Run inference 3 times, check consistency
results = []
for _ in range(3):
    result = qwen3.transcribe_page(image, do_sample=True, temperature=0.7)
    results.append(result.text)

# If all 3 match = high confidence
# If they differ = low confidence
confidence = calculate_agreement(results)
```

**Option 2: Attention Weights (Advanced)**
```python
# Extract which parts of image the model focused on
# Regions with high attention = high confidence
# Requires model modification
```

**Option 3: Use Confidence Thresholds**
```python
# Based on testing, establish thresholds:
# > 0.95 = Excellent
# 0.85-0.95 = Good
# 0.75-0.85 = Fair
# < 0.75 = Review needed
```

## ðŸ“Š Comparison: TrOCR vs Qwen3

| Feature | TrOCR | Qwen3 VLM |
|---------|-------|-----------|
| **Segmentation** | Required | âŒ None! |
| **Confidence** | Per-line, per-token | Overall page |
| **Confidence Quality** | â­â­â­â­â­ Excellent | â­â­â­ Good (estimated) |
| **Speed** | 4-8s per page | 10-30s per page |
| **Layout Handling** | Linear only | âœ… Complex layouts |
| **VRAM** | 2-4 GB | 12-16 GB |
| **Best For** | Clean documents | Historical/complex |

## ðŸš€ Testing Qwen3

### Quick Test
```bash
# Test standalone
cd C:\Users\Achim\Documents\TrOCR\dhlab-slavistik
python inference_qwen3.py
```

### GUI Test
```bash
# Launch GUI
python transcription_gui_qt.py

# Steps:
1. Load a page image
2. Select "Qwen3 VLM" tab
3. Choose "qwen3-vl-8b-old-church-slavonic"
4. Check "Estimate Confidence"
5. Click "Transcribe Page"
6. Wait for result
```

### Compare with TrOCR
```
Test same image with both:

1. TrOCR workflow:
   - Segment lines
   - Process all lines
   - Note: Line-by-line confidence

2. Qwen3 workflow:
   - Transcribe page
   - Note: Overall confidence

Compare:
- Which is more accurate?
- Which handles layout better?
- Time difference?
```

## ðŸ“‹ Available Models

Currently configured in `inference_qwen3.py`:

```python
QWEN3_MODELS = {
    "qwen3-vl-2b": {
        "base": "Qwen/Qwen3-VL-2B-Instruct",
        "adapter": None,
        "vram": "4-6 GB",
        "speed": "Fast"
    },

    "qwen3-vl-8b": {
        "base": "Qwen/Qwen3-VL-8B-Instruct",
        "adapter": None,
        "vram": "12-16 GB",
        "speed": "Medium"
    },

    "qwen3-vl-8b-old-church-slavonic": {
        "base": "Qwen/Qwen3-VL-8B-Instruct",
        "adapter": "wjbmattingly/Qwen3-VL-8B-old-church-slavonic",
        "vram": "12-16 GB",
        "speed": "Medium"
    },
}
```

**To add more:**
Just edit the dictionary and GUI will auto-detect!

## ðŸ”® Future Enhancements

### Short-term
- [ ] Save custom prompts as presets
- [ ] Batch processing for Qwen3
- [ ] Export with confidence scores
- [ ] Compare mode: TrOCR vs Qwen3 side-by-side

### Long-term
- [ ] Fine-tune Qwen3 on your Ukrainian data
- [ ] Hybrid: Qwen3 detects layout + TrOCR recognizes
- [ ] Multi-run confidence (run 3x, compare results)
- [ ] Attention visualization (show where model looked)

## ðŸ’¡ When to Use Which Model

### Use **Qwen3 VLM** When:
- âœ… Complex page layouts (multiple columns, annotations)
- âœ… Segmentation is failing with TrOCR
- âœ… Need to preserve page structure
- âœ… Historical documents with degraded text
- âœ… Have 12+ GB VRAM available
- âœ… Quality > Speed

### Use **TrOCR** When:
- âœ… Clean, line-by-line documents
- âœ… Need detailed per-line confidence
- âœ… Fast processing required
- âœ… Limited VRAM (<8 GB)
- âœ… Batch processing many pages
- âœ… Speed > Layout complexity

## ðŸ“ Key Files Modified/Created

1. **inference_qwen3.py** - New file, complete Qwen3 inference class
2. **transcription_gui_qt.py** - Modified to add Qwen3 tab and processing
3. **QWEN3_INTEGRATION_PLAN.md** - Detailed integration guide
4. **QWEN3_IMPLEMENTATION_SUMMARY.md** - This file

## âœ… Installation Requirements

```bash
# Install Qwen3 dependencies
pip install transformers>=4.37.0
pip install accelerate  # Multi-GPU support
pip install peft  # LoRA adapters
pip install bitsandbytes  # Optional: 8-bit quantization

# Test installation
python -c "from inference_qwen3 import Qwen3VLMInference; print('Qwen3 OK!')"
```

## ðŸŽ‰ Summary

**You now have:**
- âœ… Complete Qwen3 VLM integration
- âœ… Confidence score estimation (token probabilities)
- âœ… Smart GUI that adapts to model type
- âœ… No segmentation needed for Qwen3
- âœ… Multi-GPU support (perfect for your 2Ã— RTX 4090)
- âœ… Three model types in one GUI: TrOCR, PyLaia (future), Qwen3

**Next steps:**
1. Install dependencies: `pip install transformers>=4.37.0 accelerate peft`
2. Test Qwen3 standalone: `python inference_qwen3.py`
3. Launch GUI: `python transcription_gui_qt.py`
4. Try Qwen3 tab on Ukrainian page
5. Compare with TrOCR results

The confidence estimation works by extracting token probabilities during generation - while not perfect, it gives you a useful overall quality metric!
