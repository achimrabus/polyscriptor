# Configuration for Efendiev_3 dataset training
# Cyrillic handwriting (Russian)
# MULTI-GPU: 2x RTX 4090 (24GB each)

# Model configuration
model_name: "kazars24/trocr-base-handwritten-ru"  # Pre-trained Cyrillic model
max_length: 64

# Data paths
data_root: "./data/efendiev_3"  # Output from transkribus_parser.py
train_csv: "train.csv"
val_csv: "val.csv"

# Performance optimization
cache_images: false  # DISABLED: Images too large (7000Ã—657), causes OOM
num_workers: 8       # More workers for 2 GPUs
dataloader_num_workers: 8

# Training hyperparameters - OPTIMIZED FOR 2x RTX 4090
output_dir: "./models/efendiev_3_model"
batch_size: 32                      # Larger batch per GPU (32 * 2 GPUs = 64)
gradient_accumulation_steps: 2      # Effective batch size: 32*2*2 = 128
epochs: 15                          # More epochs for smaller dataset
learning_rate: 0.00004              # Slightly higher LR for larger batch (4e-5)
weight_decay: 0.01
warmup_ratio: 0.1

# Speed optimizations
fp16: true                          # Mixed precision training
gradient_checkpointing: false       # Disabled for speed

# Evaluation strategy
eval_strategy: "steps"
eval_steps: 100                     # Evaluate frequently (small dataset)
save_steps: 100
save_total_limit: 3
logging_steps: 20

# Generation settings (for evaluation)
predict_with_generate: true
generation_max_length: 64
generation_num_beams: 1  # Greedy for faster eval during training

# Data augmentation
use_augmentation: true
aug_rotation_degrees: 2
aug_brightness: 0.3
aug_contrast: 0.3

# Reproducibility
seed: 42
